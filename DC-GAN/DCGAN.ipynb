{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "import os\n",
    "\n",
    "current_time = datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "os.makedirs(os.path.dirname(\"logs/\" + current_time + \"/\"), exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "\n",
    "logger = logging.getLogger(\"gan\")\n",
    "logger.setLevel(logging.DEBUG)\n",
    "fh = logging.FileHandler(\"logs/\" + current_time + \"/gan.log\")\n",
    "fh.setLevel(logging.DEBUG)\n",
    "sh = logging.StreamHandler()\n",
    "sh.setLevel(logging.INFO)\n",
    "formatter = logging.Formatter(\"%(levelname)s - %(message)s\")\n",
    "fh.setFormatter(formatter)\n",
    "sh.setFormatter(formatter)\n",
    "logger.addHandler(fh)\n",
    "logger.addHandler(sh)\n",
    "logger.debug(\"Starting..\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Reusing TensorBoard on port 6006 (pid 21940), started 0:04:11 ago. (Use '!kill 21940' to kill it.)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-c540427d2d5dea20\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-c540427d2d5dea20\");\n",
       "          const url = new URL(\"/\", window.location);\n",
       "          url.port = 6006;\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "  "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Tensorboard extension\n",
    "%load_ext tensorboard\n",
    "\n",
    "logger.debug(\"Starting Tensorboard..\")\n",
    "%tensorboard --logdir logs/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO - TensorFlow version: 2.0.0\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import tensorflow.keras as keras\n",
    "from tensorflow.keras.datasets import mnist\n",
    "from tensorflow.keras.layers import LeakyReLU\n",
    "from packaging import version\n",
    "\n",
    "logger.info(\"TensorFlow version: %s\", tf.__version__)\n",
    "assert version.parse(tf.__version__).release[0] >= 2, \"This notebook requires TensorFlow 2.0 or above.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "if tf.test.is_built_with_cuda():\n",
    "    gpu = tf.test.is_gpu_available()\n",
    "if not gpu:\n",
    "    logger.debug(\"GPU Acceleration not available!!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "logger.debug(\"Global Variables..\")\n",
    "BATCH_SIZE = 32\n",
    "FEAT_DIM = 100\n",
    "EPOCHS = 200\n",
    "logger.debug(\"Batch Size = %d\", BATCH_SIZE)\n",
    "logger.debug(\"Dimension of images after flattening as used for training = %d\", IMG_DIM)\n",
    "logger.debug(\"Dimension of noise input used by generator to generate fakes = %d\", FEAT_DIM)\n",
    "logger.debug(\"Number of training epochs = %d\", IMG_DIM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO - Number of training examples: 60000\n",
      "INFO - Dimension of each example: (28, 28)\n",
      "INFO - Dtype of examples: uint8\n",
      "INFO - Max pixel value: 255\n",
      "INFO - Min pixel value: 0\n"
     ]
    }
   ],
   "source": [
    "logger.debug(\"Using MNIST dataset..\")\n",
    "(X_train, _), _ = mnist.load_data()\n",
    "logger.info(\"Number of training examples: %d\", X_train.shape[0])\n",
    "logger.info(\"Dimension of each example: %s\", X_train.shape[1:] if len(X_train.shape)>1 else 1)\n",
    "logger.info(\"Dtype of examples: %s\", X_train.dtype)\n",
    "logger.info(\"Max pixel value: %d\", X_train.max())\n",
    "logger.info(\"Min pixel value: %d\", X_train.min())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO - Range of X_train values: -1 to 1\n",
      "INFO - Shape of training data: 60000 x 784\n"
     ]
    }
   ],
   "source": [
    "logger.debug(\"Rescaling training values to lie between -1 and 1 (including both)..\")\n",
    "X_train = X_train.astype(float)\n",
    "X_train = (X_train-127.5)/127.5\n",
    "logger.info(\"Range of X_train values: %d to %d\", X_train.min(), X_train.max())\n",
    "\n",
    "logger.debug(\"Reshaping training data to add depth dimension in images..\")\n",
    "X_train = np.reshape(X_train, (*X_train.shape, 1))\n",
    "logger.info(\"Shape of training data: %d x %d x %d x %d\", X_train.shape[0], X_train.shape[1], X_train.shape[2], X_train.shape[3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "logger.debug(\"Mini-Batching and Shuffling dataset..\")\n",
    "train_ds = tf.data.Dataset.from_tensor_slices((X_train)).shuffle(10000).batch(BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "logger.debug(\"Defining the model for discriminator..\")\n",
    "des_in = keras.layers.Input(shape = (28, 28, 1))\n",
    "des = keras.layers.Conv2D(16, (3, 3), activation = LeakyReLU(0.2), kernel_initializer = \"he_normal\")(des_in)\n",
    "des = keras.layers.Dropout(0.3)(des)\n",
    "des = keras.layers.Dense(512, activation = LeakyReLU(0.2), kernel_initializer = \"he_normal\")(des)\n",
    "des = keras.layers.Dropout(0.3)(des)\n",
    "des = keras.layers.Dense(256, activation = LeakyReLU(0.2), kernel_initializer = \"he_normal\")(des)\n",
    "des = keras.layers.Dropout(0.3)(des)\n",
    "des = keras.layers.Dense(256, activation = LeakyReLU(0.2), kernel_initializer = \"he_normal\")(des)\n",
    "des = keras.layers.Dropout(0.3)(des)\n",
    "des_out = keras.layers.Dense(1, activation = keras.activations.sigmoid, kernel_initializer = \"he_normal\")(des)\n",
    "discriminator  = keras.Model(inputs = des_in, outputs = des_out)\n",
    "logger.debug(\"Discriminator Summary\")\n",
    "discriminator.summary(print_fn = logger.debug)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "logger.debug(\"Defining generator model..\")\n",
    "gen_in = keras.layers.Input(shape = (100, ))\n",
    "gen = keras.layers.Dense(256, activation = LeakyReLU(0.2), kernel_initializer = \"he_normal\")(gen_in)\n",
    "gen = keras.layers.Dropout(0.3)(gen)\n",
    "gen = keras.layers.Dense(512, activation = LeakyReLU(0.2), kernel_initializer = \"he_normal\")(gen)\n",
    "gen = keras.layers.Dropout(0.3)(gen)\n",
    "gen = keras.layers.Dense(1024, activation = LeakyReLU(0.2), kernel_initializer = \"he_normal\")(gen)\n",
    "gen = keras.layers.Dropout(0.3)(gen)\n",
    "gen_out = keras.layers.Dense(784, activation = keras.activations.tanh, kernel_initializer = \"he_normal\")(gen)\n",
    "generator = keras.Model(inputs = gen_in, outputs = gen_out)\n",
    "logger.debug(\"Generator Summary\")\n",
    "generator.summary(print_fn = logger.debug)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO - Visualization of untrained generator output\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x23bf5054f48>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "logger.info(\"Visualization of untrained generator output\")\n",
    "noise = tf.random.normal(shape = (1, FEAT_DIM))\n",
    "generated_img = generator(noise, training = False)\n",
    "plt.imshow(tf.reshape(generated_img[0], [28,28,1])[:,:,0], cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "logger.debug(\"Defining separate optimizers for discriminator and generator..\")\n",
    "logger.debug(\"Using ADAM optimizer for both generator and discriminator!\")\n",
    "generator_optimizer = keras.optimizers.Adam(lr = 0.0002)\n",
    "discriminator_optimizer = keras.optimizers.Adam(lr = 0.0002)\n",
    "\n",
    "logger.debug(\"Using BinaryCrossentropy for loss function\")\n",
    "cross_entropy = keras.losses.BinaryCrossentropy()\n",
    "\n",
    "# Storing the mean loss\n",
    "discriminator_loss = tf.keras.metrics.Mean(name='discriminator_loss')\n",
    "generator_loss = tf.keras.metrics.Mean(name='generator_loss')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def get_discriminator_loss(real_pred, fake_pred):\n",
    "#     real_loss = cross_entropy(tf.ones_like(real_pred), real_pred)\n",
    "#     fake_loss = cross_entropy(tf.zeros_like(fake_pred), fake_pred)\n",
    "#     total_loss = real_loss + fake_loss\n",
    "#     return total_loss\n",
    "\n",
    "# def get_generator_loss(fake_pred):\n",
    "#     fake_loss = cross_entropy(tf.ones_like(fake_pred), fake_pred)\n",
    "#     return fake_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Training function for Discriminator\n",
    "# @tf.function\n",
    "# def train(real):\n",
    "#     noise = tf.random.normal(shape = (32, 100))\n",
    "#     with tf.GradientTape() as gen_tape, tf.GradientTape() as dis_tape:\n",
    "#         fake = generator(noise, training = True)\n",
    "#         real_pred = discriminator(real, training = True)\n",
    "# #         real_loss = cross_entropy(tf.ones_like(real_pred), real_pred)\n",
    "#         fake_pred = discriminator(fake, training = True)\n",
    "# #         dis_fake_loss = cross_entropy(tf.zeros_like(fake_pred), fake_pred)\n",
    "# #         gen_fake_loss = cross_entropy(tf.ones_like(fake_pred), fake_pred)\n",
    "# #         total_loss = real_loss + dis_fake_loss\n",
    "#         dis_loss = get_discriminator_loss(real_pred, fake_pred)\n",
    "#         gen_loss = get_generator_loss(fake_pred)\n",
    "#     dis_gradient = dis_tape.gradient(dis_loss, discriminator.trainable_variables)\n",
    "#     gen_gradient = gen_tape.gradient(gen_loss, generator.trainable_variables)\n",
    "#     discriminator_optimizer.apply_gradients(zip(dis_gradient, discriminator.trainable_variables))\n",
    "    \n",
    "#     generator_optimizer.apply_gradients(zip(gen_gradient, generator.trainable_variables))\n",
    "    \n",
    "#     discriminator_loss(dis_loss)\n",
    "#     generator_loss(gen_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training function for Discriminator\n",
    "@tf.function\n",
    "def train_discriminator(real):\n",
    "    noise = tf.random.normal(shape = (32, 100))\n",
    "    with tf.GradientTape() as tape:\n",
    "        fake = generator(noise, training = False)\n",
    "        real_pred = discriminator(real, training = True)\n",
    "        real_loss = cross_entropy(tf.ones_like(real_pred), real_pred)\n",
    "        fake_pred = discriminator(fake, training = True)\n",
    "        fake_loss = cross_entropy(tf.zeros_like(fake_pred), fake_pred)\n",
    "        total_loss = real_loss + fake_loss\n",
    "    gradient = tape.gradient(total_loss, discriminator.trainable_variables)\n",
    "    discriminator_optimizer.apply_gradients(zip(gradient, discriminator.trainable_variables))\n",
    "    \n",
    "    discriminator_loss(total_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training function for Generator\n",
    "@tf.function\n",
    "def train_generator():\n",
    "    noise = tf.random.normal(shape = (32, 100))\n",
    "    with tf.GradientTape() as tape:\n",
    "        fake = generator(noise, training = True)\n",
    "        fake_pred = discriminator(fake, training = False)\n",
    "        fake_loss = cross_entropy(tf.ones_like(fake_pred), fake_pred)\n",
    "    gradient = tape.gradient(fake_loss, generator.trainable_variables)\n",
    "    generator_optimizer.apply_gradients(zip(gradient, generator.trainable_variables))\n",
    "    \n",
    "    generator_loss(fake_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_log_dir = 'logs/' + current_time + '/train'\n",
    "train_summary_writer = tf.summary.create_file_writer(train_log_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer dense is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "logger.debug(\"Beginning training..\")\n",
    "for epoch in range(EPOCHS):\n",
    "    for real in train_ds:\n",
    "#         train(real)\n",
    "        train_discriminator(real)\n",
    "        train_generator()\n",
    "    with train_summary_writer.as_default():\n",
    "        tf.summary.scalar('Discriminator loss', discriminator_loss.result(), step=epoch)\n",
    "        tf.summary.scalar('Generator loss', generator_loss.result(), step=epoch)\n",
    "    logger.debug(\"Epoch: %d - Discriminator loss: %f - Generator loss: %f\", epoch+1, discriminator_loss.result(), generator_loss.result())\n",
    "    discriminator_loss.reset_states()\n",
    "    generator_loss.reset_states()\n",
    "    if epoch%20 == 0:\n",
    "        fig, ax = plt.subplots(10, 10, figsize = (20, 20))\n",
    "        noise = tf.random.normal(shape = (100, 100))\n",
    "        generated_images = generator(noise, training = False)\n",
    "        generated_images = tf.reshape(generated_images, [100, 28, 28, 1])\n",
    "        for i in range(100):\n",
    "            ax[i//10, i%10].imshow(generated_images[i][:, :, 0], cmap = \"gray\")\n",
    "        plt.savefig(\"progress-\"+str(epoch)+\".png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(10, 10, figsize = (20, 20))\n",
    "noise = tf.random.normal(shape = (100, 100))\n",
    "generated_images = generator(noise, training = False)\n",
    "generated_images = tf.reshape(generated_images, [100, 28, 28, 1])\n",
    "for i in range(100):\n",
    "    ax[i//10, i%10].imshow(generated_images[i][:, :, 0], cmap = \"gray\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
